import cv2
import mediapipe as mp
import pyautogui
import time
import math

# Initialize MediaPipe Hands
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.5
)
mp_draw = mp.solutions.drawing_utils

scroll_amount = 40
scroll_cooldown = 0.1

# ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ‚Äî ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
    print("üí° ‡∏•‡∏≠‡∏á:")
    print("   - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô cv2.VideoCapture(1)")
    print("   - ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà (Zoom, Teams, Camera app)")
    print("   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
    exit()
else:
    print("‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚Äî ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")

last_gesture = None
last_scroll_time = 0

while cap.isOpened():
    success, image = cap.read()
    if not success:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‚Äî ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô")
        time.sleep(1)
        continue

    image = cv2.flip(image, 1)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = hands.process(image_rgb)

    current_gesture = "stop"

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_draw.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Landmarks ‡∏Ç‡∏≠‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ
            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]
            index_pip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP]
            index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]

            # Landmarks ‡∏Ç‡∏≠‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
            middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]
            ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]
            pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]

            middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]
            ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]
            pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]

            # ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∏‡∏î 2 ‡∏à‡∏∏‡∏î
            def distance(p1, p2):
                return math.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)

            # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö "‡∏Å‡∏≥‡∏°‡∏∑‡∏≠" ‡πÅ‡∏ö‡∏ö‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
            index_length = distance(index_mcp, index_tip)
            index_full_length = distance(index_mcp, index_pip) * 2.5

            middle_length = distance(middle_mcp, middle_tip)
            middle_full_length = distance(middle_mcp, hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP]) * 2.5

            ring_length = distance(ring_mcp, ring_tip)
            ring_full_length = distance(ring_mcp, hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP]) * 2.5

            pinky_length = distance(pinky_mcp, pinky_tip)
            pinky_full_length = distance(pinky_mcp, hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP]) * 2.5

            fist_threshold = 0.6

            is_fist = (
                index_length < index_full_length * fist_threshold and
                middle_length < middle_full_length * fist_threshold and
                ring_length < ring_full_length * fist_threshold and
                pinky_length < pinky_full_length * fist_threshold
            )

            if is_fist:
                current_gesture = "stop"
            else:
                # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ô‡∏¥‡πâ‡∏ß‡∏≠‡∏∑‡πà‡∏ô‡∏û‡∏±‡∏ö
                others_folded = (
                    middle_tip.y > index_pip.y and
                    ring_tip.y > index_pip.y and
                    pinky_tip.y > index_pip.y
                )

                if others_folded:
                    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ‡πÄ‡∏´‡∏¢‡∏µ‡∏¢‡∏î‡∏û‡∏≠
                    if index_length > index_full_length * 0.7:
                        dx = index_tip.x - index_pip.x
                        dy = index_tip.y - index_pip.y

                        angle_rad = math.atan2(dx, -dy)
                        angle_deg = math.degrees(angle_rad)
                        if angle_deg < 0:
                            angle_deg += 360

                        if angle_deg < 30 or angle_deg > 330:
                            current_gesture = "scroll_up"
                        elif 150 < angle_deg < 210:
                            current_gesture = "scroll_down"
                        else:
                            current_gesture = "stop"
                    else:
                        current_gesture = "stop"
                else:
                    current_gesture = "stop"

    # üñ±Ô∏è Execute scroll
    current_time = time.time()
    if current_gesture != last_gesture or (current_time - last_scroll_time > scroll_cooldown):
        if current_gesture == "scroll_up":
            pyautogui.scroll(scroll_amount)
        elif current_gesture == "scroll_down":
            pyautogui.scroll(-scroll_amount)

        last_gesture = current_gesture
        last_scroll_time = current_time

    # üìä ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ gesture ‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ‚Äî ‡πÑ‡∏°‡πà‡∏°‡∏µ debug info
    cv2.putText(image, f"Status: {current_gesture.upper()}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # üñºÔ∏è ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û
    cv2.imshow('Hand Gesture Control', image)

    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö refresh ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á
    key = cv2.waitKey(1)
    if key & 0xFF == ord('q'):
        break

# ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á
cap.release()
cv2.destroyAllWindows()
print("üëã ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")